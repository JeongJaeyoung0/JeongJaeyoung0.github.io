---
layout: post
title: "[AI] ML - 머신러닝 지도학습 분류 앙상블"
subtitle: "SupervisedLearning05"
categories: python
tags: ai
comments: true
---
# 머신러닝 지도학습 분류 앙상블

### 앙상블 개념

알고리즘을 결합하여 예측 성능 향상

### 앙상블 학습 유형

- 보팅(Voting): 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식 (일반적으로 서로 다른 알고리즘을 가진 분류기를 결합)
    - 하드 보팅(Hard Voting): 다수결 원칙과 비슷, 다수의 분류기가 결정한 예측값을 최종 보팅 결괏값으로 선정
    - 소프트 보팅(Soft Voting): 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결괏값으로 선정 (일반적으로 많이 사용)
- 배깅(Bagging): 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식 (일반적으로 서로 같은 유형의 알고리즘 분류기지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 수행하는 것으로 대표적으로 랜덤 포레스트가 있음)
- 부스팅(Boosting): 여러 개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에게는 가중치(weight)를 부여하면서 학습과 예측을 진행 (대표적으로 그래디언트 부스트, XGBoost, LightGBM)
- 스태킹(Stacking): 여러 가지 다른 모델의 예측 결괏값을 다시 학습 데이터로 만들어서 다시 학습 데이터로 만들어서 다른 모델(메타 모델)로 재학습시켜 결과를 예측하는 방식
- 등

<br>

### 앙상블 학습 종류
- RandomForest
    - 배깅 유형
    - 여러 개의 결정트리에 데이터 세트를 랜덤하게 중첩되게 분리(부트스트래핑, bootstrapping)하여 학습
- GBM(Gradient Boost Machine)
    - 부스팅 유형
    - 회귀도 가능
    - 경사 하강법을 이용하여 가중치 업데이트
- XGBoost(eXtra Gradient Boost)
    - 부스팅 유형
    - 트리 기반의 앙상블 학습
    - GBM 기반이지만 느린 수행 시간 및 과적합 규제 부재 등의 문제를 해결해서 각광 받고 있음
    - 병렬 CPU 환경에서 병렬 학습이 가능해 GBM보다 빠른 학습
- LightGBM
    - 부스팅 유형
    - XGBoost와 함께 각광 받고 있음
    - XGBoost보다 학습에 걸리는 시간이 훨씬 적음
    - 적은 데이터 세트(10,000건 이하)에 적용할 경우 과적합이 발생하기 쉬움
    - 카테고리형 피처의 자동 변환과 최적화(원-핫 인코딩 등을 사용하지 않고도 카테고리형 피처를 최적으로 변환하고 이에 따른 노드 분할 수행)