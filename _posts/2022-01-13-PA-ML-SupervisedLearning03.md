---
layout: post
title: "[AI] ML - 머신러닝 데이터 전처리"
subtitle: "SupervisedLearning03"
categories: python
tags: ai
comments: true
---

# 데이터 전처리
- ML 알고리즘만큼 중요함, 데이터 기반이기 때문
- 결손값(NaN, Null) 값 처리 (드롭, 평균, 최소, 최대 등 방법으로 처리)
- 데이터 인코딩
- 데이터 스케일링, 정규화

<br>

### 데이터 인코딩
- 레이블 인코딩
    - 카테고리 피처를 코드형 숫자 값으로 변환
    - 몇몇 ML 알고리즘에는 예측 성능이 떨어지는 경우 발생할 수 있음(숫자 값이 크고 작음에 대한 특성이 적용되기 때문)
    - 선형회귀와 같은 ML 알고리즘에는 적용하지 않아야함
    - 트리 계열의 ML 알고리즘은 숫자의 특성이 반영하지 않으므로 별문제가 없음

- 원-핫 인코딩
    - 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식
    - 단어의 개수가 늘어날 수록 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점이 있음
    - 단어의 유사도를 표현하지 못한다는 단점이 있음 (검색 시스템에서 문제가 될 소지가 있음)
        - 해결 방법: 단어의 잠재 의미를 반영하여 다차원 공간에 벡터화 하는 기법
            - 첫째, 카운트 기반의 벡터화 방법인 LSA(잠재 의미 분석), HAL 등
            - 둘째, 예측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText 등
            - 카운트 기반과 예측 기반 두 가지 방법을 모두 사용하는 방법인 GloVe

* * *

# 피처 스케일링과 정규화
- 피처 스케일링: 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업
    - 표준화: 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환
    - 정규화: 서로 다른 피처의 크기를 통일하기 위해 크기를 0~1 값으로 변환해주는 개념 (ex: 키, 나이)
    > 사이킷런의 전처리에서 제공하는 Normalizer 모듈과 일반적인 정규화는 개념은 같지만 약간의 차이가 있다. 사이킷런의 모듈은 선형대수에서의 정규화 개념이 적용됐으며, 개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미한다.<br>
    > 일반적인 의미의 표준화와 정규화를 피처 스케일링으로 통칭하며, 선형대수 개념의 정규화를 벡터 정규화로 지칭한다.

<br>

### StandardScaler
- 표준화(가우시안 정규 분포)를 쉽게 지원하기 위한 클래스
- 사이킷런에서 구현한 RBF 커널을 이용하는 서포트 벡터 머신, 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 사전에 표준화 적용하는 것이 중요

<br>

### MinMaxScaler
- 정규화(데이터값을 0과 1사이의 범위 값으로 변환. 음수 값이 있으면 -1에서 1값으로 변환)
- 데이터의 분포가 가우시안 분포가 아닐 경우 Min, Max Scale을 적용해 볼 수 있음

<br>

### 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점
- 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리
- 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler객체를 이용해 transform()으로 변환